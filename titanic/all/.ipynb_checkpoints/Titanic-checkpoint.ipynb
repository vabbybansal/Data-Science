{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import average_precision_score, auc, roc_curve, precision_recall_curve, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from tqdm import *\n",
    "from ggplot import *\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "test_dumm = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a sense of the data\n",
    "print train.info()\n",
    "# print train.describe()\n",
    "# print train.describe(include=['O'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set one row of fare is null - find value\n",
    "print test[test['Fare'].isnull() == True]\n",
    "\n",
    "# Assign the mean value in the same embarkment, class\n",
    "test.at[152,'Fare'] = test[(test['Embarked'] == 'S') & (test['Pclass'] == 3) & (test['Fare'].isnull() == False) & (test['Age'].isnull() == False)]['Age'].mean()\n",
    "\n",
    "print test.iloc[152]['Fare']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explorations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure()\n",
    "plt.subplot(2,2,1)\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Freq')\n",
    "plt.title('Distribution of Age')\n",
    "plt.hist(np.array(train['Age'][train['Age'].isnull() == False]), bins = 100)\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.xlabel('Fare')\n",
    "plt.ylabel('Freq')\n",
    "plt.title('Distribution of Fare')\n",
    "plt.hist(np.array(train['Fare'][train['Fare'].isnull() == False]), bins = 100)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the heatmap and annotation on it\n",
    "import seaborn as sns\n",
    "Var_Corr = train[['Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare']].corr()\n",
    "sns.heatmap(Var_Corr, xticklabels=Var_Corr.columns, yticklabels=Var_Corr.columns, annot=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# train[train['SibSp'] > 1].sort_values(['Ticket'])\n",
    "# The fair seems to be individual and not grouped (for people with family)\n",
    "# Mostly the tickets seem to be same for grouped people, but they are different as well for some groups (Gustafsson)\n",
    "# Fare seems to be priced differentiated among people with same class and provisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore relationships with age to impute the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Age with Pclass\n",
    "sns.kdeplot(train[train['Pclass'] == 1]['Age'], shade=True, color='r');\n",
    "sns.kdeplot(train[train['Pclass'] == 2]['Age'], shade=True, color='b');\n",
    "sns.kdeplot(train[train['Pclass'] == 3]['Age'], shade=True, color='g');\n",
    "print train.groupby('Pclass')['Age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Age with Sibsp\n",
    "\n",
    "sns.kdeplot(train[train['SibSp'] == 0]['Age'], shade=True, color='black');\n",
    "sns.kdeplot(train[train['SibSp'] == 1]['Age'], shade=True, color='blue');\n",
    "sns.kdeplot(train[train['SibSp'] == 2]['Age'], shade=True, color='red');\n",
    "print train['SibSp'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Age for Parch\n",
    "sns.kdeplot(train[train['Parch'] == 0]['Age'], shade=True, color='black');\n",
    "sns.kdeplot(train[train['Parch'] == 1]['Age'], shade=True, color='blue');\n",
    "sns.kdeplot(train[train['Parch'] == 2]['Age'], shade=True, color='red');\n",
    "\n",
    "train['Parch'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at combinations\n",
    "sns.kdeplot(train[(train['Parch'] == 0)&(train['SibSp'] == 0)&(train['Pclass'] == 1)]['Age'], shade=True, color='blue');\n",
    "sns.kdeplot(train[(train['Parch'] == 0)&(train['SibSp'] == 0)&(train['Pclass'] == 2)]['Age'], shade=True, color='yellow');\n",
    "sns.kdeplot(train[(train['Parch'] == 0)&(train['SibSp'] == 0)&(train['Pclass'] == 3)]['Age'], shade=True, color='pink');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(train, row='Pclass', col='Sex')\n",
    "g.map(plt.hist, \"Age\")\n",
    "age_pclass_medians = train.groupby(['Pclass', 'Sex'])['Age'].median()\n",
    "print age_pclass_medians"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  Looks like age can be segmented from combination of pclass and sex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineer Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# Use this code to check if all titles are there in the list\n",
    "def check_title(name):\n",
    "    x = False\n",
    "    for title in ['Mr.', 'Master.', 'Miss.', 'Mrs.', 'Rev.', 'Don.', 'Dona.', 'Dr.', 'Mme.', 'Ms.', 'Major.', 'Lady.', 'Sir.', 'Mlle.', 'Jonkheer.', 'Col.', 'Countess.', 'Capt.']:\n",
    "        x = title in name\n",
    "        if x:\n",
    "            break\n",
    "    return x\n",
    "\n",
    "for i in range(len(test['Name'])):\n",
    "    if check_title(test['Name'][i]) == False:\n",
    "        print test['Name'][i]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to get title column\n",
    "def get_title(name):\n",
    "    x = False\n",
    "    for title in ['Mr.', 'Master.', 'Miss.', 'Mrs.', 'Rev.', 'Don.', 'Dona.', 'Dr.', 'Mme.', 'Ms.', 'Major.', 'Lady.', 'Sir.', 'Mlle.', 'Jonkheer.', 'Col.', 'Countess.', 'Capt.']:\n",
    "        x = title in name\n",
    "        if x:\n",
    "            break\n",
    "    return title\n",
    "# for i in range(len(test['Name'])):\n",
    "#     print check_title(test['Name'][i])\n",
    "train['title'] = train[['Name']].apply(lambda x: get_title(*x), axis=1)\n",
    "test['title'] = test[['Name']].apply(lambda x: get_title(*x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the survival rates of the titles\n",
    "pd.concat([train.groupby('title')['Survived'].mean(), train.groupby('title')['Survived'].count()], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remap the title relationships\n",
    "title_map = {\n",
    "    'Capt.': 'Other',\n",
    "    'Col.': 'Other',\n",
    "    'Countess.': 'Royal',\n",
    "    'Don.': 'Royal',\n",
    "    'Dr.': 'Other',\n",
    "    'Jonkheer.': 'Royal',\n",
    "    'Lady.': 'Royal',\n",
    "    'Major.': 'Other',\n",
    "    'Mlle.': 'Miss.',\n",
    "    'Mme.': 'Mr.',\n",
    "    'Ms.': 'Miss.',\n",
    "    'Rev.': 'Rev',\n",
    "    'Sir.': 'Royal',\n",
    "    'Dona.': 'Royal'\n",
    "}\n",
    "train['title'] = train.replace({'title': title_map})['title']\n",
    "test['title'] = test.replace({'title': title_map})['title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute age as very low for 'Master' title (4 missing values)\n",
    "g = sns.FacetGrid(test, col='title')\n",
    "g.map(plt.hist, 'Age')\n",
    "train[\n",
    "    (train['title'] == 'Master.')\n",
    "    & (train['Age'].isnull() == True)\n",
    "]\n",
    "\n",
    "# This shouldn't but its reducing accuracy for some reason, so not doing\n",
    "# train.loc[(train['title'] == 'Master.')& (train['Age'].isnull() == True),'Age'] = train[(train['title'] == 'Master.')]['Age'].mean()\n",
    "# test.loc[(test['title'] == 'Master.')& (test['Age'].isnull() == True),'Age'] = train[(train['title'] == 'Master.')]['Age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Assign null ages to median values from segments of Pclass and sex\n",
    "age_pclass_medians\n",
    "\n",
    "# Function to create the age val from pclass and sex\n",
    "def calAge(pclass, sex):\n",
    "    return age_pclass_medians.loc[(age_pclass_medians.index.get_level_values('Pclass') == pclass) & (age_pclass_medians.index.get_level_values('Sex') == sex)].values[0]\n",
    "\n",
    "# Use apply function on the two columns to get the new missing age vals\n",
    "created_age_vals_TRAIN = train[train['Age'].isnull()][['Pclass','Sex']].apply(lambda x: calAge(*x), axis = 1)\n",
    "created_age_vals_TEST = test[test['Age'].isnull()][['Pclass','Sex']].apply(lambda x: calAge(*x), axis = 1)\n",
    "\n",
    "# Append given ages with created ages\n",
    "new_age_TRAIN = train[train['Age'].isnull() == False]['Age'].append(created_age_vals_TRAIN)\n",
    "new_age_TEST = test[test['Age'].isnull() == False]['Age'].append(created_age_vals_TEST)\n",
    "\n",
    "# concat the new age to the old age using index\n",
    "# new_age\n",
    "train = pd.concat([train.drop(['Age'], axis = 1), pd.DataFrame(new_age_TRAIN, columns=['Age'])], axis =1)\n",
    "test = pd.concat([test.drop(['Age'], axis = 1), pd.DataFrame(new_age_TEST, columns=['Age'])], axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is_alone feature?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commenting out because this was not very helpful ~ gets accounted for in the num_dependents feature\n",
    "# train['isAlone'] = train[['SibSp', 'Parch']].apply(lambda x: 1 if ((x['SibSp'] == 0) and (x['Parch'] == 0)) else 0, axis=1)\n",
    "# test['isAlone'] = test[['SibSp', 'Parch']].apply(lambda x: 1 if ((x['SibSp'] == 0) and (x['Parch'] == 0)) else 0, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## num_dependents feature?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aka Family Size\n",
    "train['num_dependents'] = train[['SibSp', 'Parch']].apply(lambda x: ((x['SibSp']) + (x['Parch'])), axis=1)\n",
    "test['num_dependents'] = test[['SibSp', 'Parch']].apply(lambda x: ((x['SibSp']) + (x['Parch'])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check survival rates acc to num_dependents\n",
    "g = sns.FacetGrid(train, col='num_dependents')\n",
    "g.map(plt.hist, 'Survived')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  Looks definitely promising"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## premium_over_class_avg?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check how many people paid more than the mean payment of their classes \n",
    "meanFares = train.groupby('Pclass')['Fare'].mean()\n",
    "\n",
    "train['premium_over_mean_ticket'] = train[['Pclass', 'Fare']].apply(lambda x: 1 if ((x['Fare'] - meanFares.loc[x['Pclass']]) >0) else 0, axis=1)\n",
    "test['premium_over_mean_ticket'] = test[['Pclass', 'Fare']].apply(lambda x: 1 if ((x['Fare'] - meanFares.loc[x['Pclass']]) >0) else 0, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous to Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_dependents\n",
    "g = sns.FacetGrid(train, col='num_dependents')\n",
    "g.map(plt.hist, 'Survived')\n",
    "\n",
    "# Reassign titles and make less frequent titles to 'Other'\n",
    "title_map = {\n",
    "    0: 'alone',\n",
    "    1: 'couple',\n",
    "    2: 'small',\n",
    "    3: 'mid',\n",
    "    4: 'mid',\n",
    "    5: 'large',\n",
    "    6: 'large',\n",
    "    7: 'large',\n",
    "    8: 'large',\n",
    "    9: 'large',\n",
    "    10: 'large'\n",
    "}\n",
    "train['num_dependents'] = train.replace({'num_dependents': title_map})['num_dependents']\n",
    "test['num_dependents'] = test.replace({'num_dependents': title_map})['num_dependents']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  This helped increase the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fare\n",
    "g = sns.FacetGrid(train, col='Survived')\n",
    "plott = g.map(plt.hist, 'Fare', bins=200)\n",
    "axs = plott.axes\n",
    "axs[0,0].set_xlim(0,100)\n",
    "train.groupby('Survived')['Fare'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['fare_categ'] = train[['Fare']].apply(lambda x: 'low' if x['Fare'] < 20 else 'high', axis = 1)\n",
    "test['fare_categ'] = test[['Fare']].apply(lambda x: 'low' if x['Fare'] < 20 else 'high', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsampling?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "random.seed(101)\n",
    "# Class distribution?\n",
    "train['Survived'].value_counts()\n",
    "\n",
    "# Try Downsampling the data \n",
    "def downSample(df, y):\n",
    "    majorityClass = df[y].value_counts().idxmax()\n",
    "    minorityClass = df[y].value_counts().idxmin()\n",
    "    \n",
    "    dfMajority = df[df[y] == majorityClass]\n",
    "    dfMinority = df[df[y] == minorityClass]\n",
    "    \n",
    "    dfMajorityDownSampled = resample(dfMajority, \n",
    "                                 replace=False,    # sample without replacement\n",
    "                                 n_samples=dfMinority.shape[0],     # to match minority class\n",
    "                                 random_state=123) # reproducible results\n",
    "    return pd.concat([dfMajorityDownSampled, dfMinority])\n",
    "\n",
    "downSample(train, 'Survived')['Survived'].value_counts()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitizeRF(df):\n",
    "    \n",
    "    # Remove Columns that do not make sense for modelling\n",
    "    dropCols = ['PassengerId', 'Name', 'Ticket'\n",
    "                , 'Cabin'\n",
    "               ]\n",
    "    df = df.drop(dropCols, axis = 1)\n",
    "    \n",
    "    # Change data types to object for dummification\n",
    "    df['Pclass'] = df['Pclass'].astype('object')\n",
    "    \n",
    "    # Dummify object type columns\n",
    "    df_Dumm = pd.get_dummies(df, columns=df.dtypes[df.dtypes == 'object'].index\n",
    "#                              , drop_first=True\n",
    "                            )\n",
    "    return df_Dumm\n",
    "\n",
    "train = sanitizeRF(train)\n",
    "test = sanitizeRF(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for model fit\n",
    "y = train['Survived']\n",
    "X = train.loc[:,train.columns != 'Survived']\n",
    "dropCols = []\n",
    "X = X.drop(dropCols, axis=1)\n",
    "print X.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random.seed(101)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25) # 70% training and 30% test\n",
    "# Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100, max_depth=5, max_features=3, random_state=101)\n",
    "cv_acc = cross_val_score(clf, X, y, cv=10, scoring='accuracy')\n",
    "cv_acc.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Grid Search for Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search Hyper Parameter Tuning\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 2000, num = 20)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(3, 10, num = 7)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10, 20, 50]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4, 10, 20]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 200, cv = 5, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check accuracy from the new parameters\n",
    "clf=RandomForestClassifier(n_estimators=1371, max_depth=7, max_features=4, bootstrap=True,min_samples_leaf=1, min_samples_split=40, random_state=101)\n",
    "cv_acc = cross_val_score(clf, X, y, cv=10, scoring='accuracy')\n",
    "cv_acc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Narrow down search by trying all combinations in a particular region\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [ 5,7],\n",
    "    'max_features': [2, 4,6],\n",
    "    'min_samples_leaf': [1],\n",
    "    'min_samples_split': [40, 50,70],\n",
    "    'n_estimators': [500,1371,1500]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestClassifier()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)\n",
    "grid_search.fit(X, y)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot probability threshold curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "# Choosing the threshold for max accuracy\n",
    "def plot_prob_thresh(pred_probs, y_test):\n",
    "    threshs = {}\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for x in range(100):\n",
    "        thresh = x/float(100) + .01\n",
    "        preds = (pred_probs > thresh).astype('int')\n",
    "        threshs[thresh] = metrics.accuracy_score(y_test, preds)\n",
    "        xs.append(thresh)\n",
    "        ys.append(threshs[thresh])\n",
    "    print max(threshs.iteritems(), key=operator.itemgetter(1))[0]\n",
    "    print threshs[max(threshs.iteritems(), key=operator.itemgetter(1))[0]]\n",
    "    threshdf = pd.concat([pd.Series(xs),pd.Series(ys)], axis=1) # Axis =1 for concatenation along the columns. For row append, axis = 0 (adding rows: 0, adding cols = 1)\n",
    "    threshdf.columns=['x','y']\n",
    "    main_thresh = max(threshs.iteritems(), key=operator.itemgetter(1))[0]\n",
    "    print ggplot(aes(x='x', y='y'), threshdf) + geom_line() + geom_point()\n",
    "\n",
    "# plot_prob_thresh(y_pred[:,1], y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "cv_dict={}\n",
    "xs = []\n",
    "ys = []\n",
    "ysd = []\n",
    "for i in tqdm(range(15)):\n",
    "    param = (i+1)\n",
    "    clf=RandomForestClassifier(n_estimators=45, max_depth=6, max_features=param)\n",
    "#     clf=RandomForestClassifier(n_estimators=60, max_depth=4, max_features=3)\n",
    "#     scores = cross_val_score(clf, X, y, cv=10, scoring='roc_auc')\n",
    "    scores = cross_val_score(clf, X, y, cv=10, scoring='accuracy')\n",
    "    cv_dict[param] = scores.mean()\n",
    "    xs.append(param)\n",
    "    ys.append(cv_dict[param])\n",
    "    ysd.append(scores.std())\n",
    "# print cv_dict\n",
    "cv = pd.concat([pd.Series(xs),pd.Series(ys), pd.Series(['auc']*len(xs))], axis=1) # Axis =1 for concatenation along the columns. For row append, axis = 0 (adding rows: 0, adding \n",
    "cv.columns=['x','y','met']\n",
    "# ggplot(aes(x='x', y='y'), cv) + geom_line() + geom_point()\n",
    "\n",
    "# print cv_dict\n",
    "cv1 = pd.concat([pd.Series(xs),pd.Series(ysd), pd.Series(['sd']*len(xs))], axis=1) # Axis =1 for concatenation along the columns. For row append, axis = 0 (adding rows: 0, adding cols = 1)\n",
    "cv1.columns=['x','y', 'met']\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(cv['x'], cv['y'])\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(cv1['x'], cv1['y'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction on the main test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=RandomForestClassifier(n_estimators=1371, max_depth=7, max_features=4, bootstrap=True,min_samples_leaf=1, min_samples_split=40, random_state=101)\n",
    "clf.fit(X,y)\n",
    "# Get prob scores for the main test set\n",
    "# y_pred_main=clf.predict_proba(test)\n",
    "# main_preds = (y_pred_main[:,1] > main_thresh).astype('int')\n",
    "# main_preds = (y_pred_main[:,1] > .57).astype('int')\n",
    "y_pred_main=clf.predict(test)\n",
    "main_preds = y_pred_main\n",
    "predDF = pd.DataFrame(test_dumm['PassengerId'])\n",
    "predDF['Survived'] = main_preds\n",
    "predDF.to_csv('preds_Oct21_NN_embeddings.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importances\n",
    "feature_importances = pd.DataFrame(clf.feature_importances_,\n",
    "                                   index = X.columns,\n",
    "                                    columns=['importance']).sort_values('importance',                                                                 ascending=False)\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Manual inspection\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25) # 70% training and 30% test\n",
    "# clf=RandomForestClassifier(n_estimators=1371, max_depth=7, max_features=4, bootstrap=True,min_samples_leaf=1, min_samples_split=40, random_state=101)\n",
    "# # cv_acc = cross_val_score(clf, X, y, cv=10, scoring='accuracy')\n",
    "# # clf.fit(X,y)\n",
    "# # cv_acc.mean()\n",
    "# clf.fit(X_train,y_train)\n",
    "# # Get prob scores for the main test set\n",
    "# # y_pred_main=clf.predict_proba(test)\n",
    "# y_pred_main=clf.predict(X_test)\n",
    "# test_manual = X_test.copy()\n",
    "# test_manual['preds'] = y_pred_main\n",
    "# test_manual['labels'] = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2) # 70% training and 30% test\n",
    "gbm = xgb.XGBClassifier(max_depth=4, n_estimators=300, learning_rate=0.05).fit(X_train, y_train)\n",
    "# predictions = gbm.predict(test_X)\n",
    "y_pred=gbm.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do data scaling\n",
    "X_Scaled = X.copy()\n",
    "scaler = StandardScaler()\n",
    "X_Scaled = scaler.fit_transform(X_Scaled)\n",
    "X_mainTest = scaler.fit_transform(test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_Scaled, y, test_size=0.2) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    # Create Model\n",
    "    model = Sequential()\n",
    "    # One hidden layer with num hidden units the same as num_pixels, with relu units\n",
    "    model.add(Dense(X.shape[1], input_dim=X.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "    # model.add(Dense(X.shape[1], input_dim=X.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "    # Output layer with softmax units (10)\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    # Compile Model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = baseline_model()\n",
    "\n",
    "# Fit the model\n",
    "# We can now fit and evaluate the model. The model is fit over 10 epochs with updates every 200 images. The test data is used as the validation dataset, allowing you to see the skill of the model as it trains. A verbose value of 2 is used to reduce the output to one line for each training epoch.\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=500, batch_size=3, verbose=2)\n",
    "\n",
    "# Evaluate the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_mainTest)\n",
    "int_preds = (preds > .47).astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create AutoEncoder representations from the titanic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import math\n",
    "print(\"Tensorflow version \" + tf.__version__)\n",
    "tf.set_random_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata = X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do data scaling\n",
    "X_Scaled = X.copy()\n",
    "scaler = StandardScaler()\n",
    "X_Scaled = scaler.fit_transform(X_Scaled)\n",
    "X_Scaled = X_Scaled.astype('float32')\n",
    "X_mainTest = scaler.fit_transform(test)\n",
    "X_mainTest = X_mainTest.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iiiiiiiii\n",
    "# *********\n",
    "#   *****\n",
    "# *********\n",
    "# iiiiiiiii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_encoded_units = 3\n",
    "\n",
    "X_ = tf.placeholder(tf.float32, [None, X_Scaled.shape[1]])\n",
    "Y_ = tf.placeholder(tf.float32, [None, X_Scaled.shape[1]])\n",
    "\n",
    "# 1st hidden layer\n",
    "W1 = tf.Variable(tf.truncated_normal([X_Scaled.shape[1], X_Scaled.shape[1]], stddev=0.1))\n",
    "B1 = tf.Variable(tf.ones([X_Scaled.shape[1]])/10)\n",
    "\n",
    "# 2nd hidden layer\n",
    "W2 = tf.Variable(tf.truncated_normal([X_Scaled.shape[1], num_encoded_units], stddev=0.1))\n",
    "B2 = tf.Variable(tf.ones([num_encoded_units])/10)\n",
    "\n",
    "# 3rd hidden layer\n",
    "W3 = tf.Variable(tf.truncated_normal([num_encoded_units, X_Scaled.shape[1]], stddev=0.1))\n",
    "B3 = tf.Variable(tf.ones([X_Scaled.shape[1]])/10)\n",
    "\n",
    "Y1 = tf.nn.relu(tf.matmul(X_, W1) + B1)\n",
    "Y2 = tf.nn.relu(tf.matmul(Y1, W2) + B2)\n",
    "Y3 = tf.nn.relu(tf.matmul(Y2, W3) + B3)\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(Y3))\n",
    "train_step=tf.train.AdamOptimizer(.01).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init=tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0\n",
    "for i in range(1000):\n",
    "    train_data={X_: X_Scaled, Y_:X_Scaled}\n",
    "    \n",
    "    sess.run(train_step, feed_dict=train_data)\n",
    "    l = sess.run([loss], feed_dict=train_data)\n",
    "    print l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get values of the hidden representation\n",
    "y1 = sess.run(tf.nn.relu(tf.matmul(X_Scaled, W1) + B1))\n",
    "y2 = sess.run(tf.nn.relu(tf.matmul(y1, W2) + B2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_maintest = sess.run(tf.nn.relu(tf.matmul(X_mainTest, W1) + B1))\n",
    "y2_maintest = sess.run(tf.nn.relu(tf.matmul(y1_maintest, W2) + B2))\n",
    "test['encoded1'] = y2_maintest[:,0]\n",
    "test['encoded2'] = y2_maintest[:,1]\n",
    "test['encoded3'] = y2_maintest[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['encoded1'] = y2[:,0]\n",
    "X['encoded2'] = y2[:,1]\n",
    "X['encoded3'] = y2[:,2]\n",
    "X.shape\n",
    "Xn = X[['encoded1', 'encoded2', 'encoded3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the new embeddings to the existing data set to check if the accuracy imporves\n",
    "clf=RandomForestClassifier(n_estimators=1000, max_depth=4, max_features=2, bootstrap=True,min_samples_leaf=1, min_samples_split=40, random_state=101)\n",
    "cv_acc = cross_val_score(clf, X, y, cv=10, scoring='accuracy')\n",
    "cv_acc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
